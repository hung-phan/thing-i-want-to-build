{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Autoencoder for PCA - EXERCISE \n",
    "\n",
    "** Follow the bold instructions below to reduce a 30 dimensional data set for classification into a 2-dimensional dataset! Then use the color classes to see if you still kept the same level of class separation in the dimensionality reduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "** Import numpy, matplotlib, and pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use pandas to read in the csv file called anonymized_data.csv . It contains 500 rows and 30 columns of anonymized data along with 1 last column with a classification label, where the columns have been renamed to 4 letter codes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anonymized_data = pd.read_csv('./anonymized_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EJWY</th>\n",
       "      <th>VALM</th>\n",
       "      <th>EGXO</th>\n",
       "      <th>HTGR</th>\n",
       "      <th>SKRF</th>\n",
       "      <th>NNSZ</th>\n",
       "      <th>NYLC</th>\n",
       "      <th>GWID</th>\n",
       "      <th>TVUT</th>\n",
       "      <th>CJHI</th>\n",
       "      <th>...</th>\n",
       "      <th>LKKS</th>\n",
       "      <th>UOBF</th>\n",
       "      <th>VBHE</th>\n",
       "      <th>FRWU</th>\n",
       "      <th>NDYZ</th>\n",
       "      <th>QSBO</th>\n",
       "      <th>JDUB</th>\n",
       "      <th>TEVK</th>\n",
       "      <th>EZTM</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.032145</td>\n",
       "      <td>1.019576</td>\n",
       "      <td>-9.658715</td>\n",
       "      <td>-6.210495</td>\n",
       "      <td>3.156823</td>\n",
       "      <td>7.457850</td>\n",
       "      <td>-5.313357</td>\n",
       "      <td>8.508296</td>\n",
       "      <td>3.959194</td>\n",
       "      <td>-5.246654</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.209663</td>\n",
       "      <td>-10.340123</td>\n",
       "      <td>-7.697555</td>\n",
       "      <td>-5.932752</td>\n",
       "      <td>10.872688</td>\n",
       "      <td>0.081321</td>\n",
       "      <td>1.276316</td>\n",
       "      <td>5.281225</td>\n",
       "      <td>-0.516447</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.306217</td>\n",
       "      <td>6.649376</td>\n",
       "      <td>-0.960333</td>\n",
       "      <td>-4.094799</td>\n",
       "      <td>8.738965</td>\n",
       "      <td>-3.458797</td>\n",
       "      <td>7.016800</td>\n",
       "      <td>6.692765</td>\n",
       "      <td>0.898264</td>\n",
       "      <td>9.337643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851793</td>\n",
       "      <td>-9.678324</td>\n",
       "      <td>-6.071795</td>\n",
       "      <td>1.428194</td>\n",
       "      <td>-8.082792</td>\n",
       "      <td>-0.557089</td>\n",
       "      <td>-7.817282</td>\n",
       "      <td>-8.686722</td>\n",
       "      <td>-6.953100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.570842</td>\n",
       "      <td>6.985462</td>\n",
       "      <td>-1.842621</td>\n",
       "      <td>-1.569599</td>\n",
       "      <td>10.039339</td>\n",
       "      <td>-3.623026</td>\n",
       "      <td>8.957619</td>\n",
       "      <td>7.577283</td>\n",
       "      <td>1.541255</td>\n",
       "      <td>7.161509</td>\n",
       "      <td>...</td>\n",
       "      <td>1.376085</td>\n",
       "      <td>-8.971164</td>\n",
       "      <td>-5.302191</td>\n",
       "      <td>2.898965</td>\n",
       "      <td>-8.746597</td>\n",
       "      <td>-0.520888</td>\n",
       "      <td>-7.350999</td>\n",
       "      <td>-8.925501</td>\n",
       "      <td>-7.051179</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.139972</td>\n",
       "      <td>0.579422</td>\n",
       "      <td>-9.526530</td>\n",
       "      <td>-5.744928</td>\n",
       "      <td>4.834355</td>\n",
       "      <td>5.907235</td>\n",
       "      <td>-4.804137</td>\n",
       "      <td>6.798810</td>\n",
       "      <td>5.403670</td>\n",
       "      <td>-7.642857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270571</td>\n",
       "      <td>-8.640988</td>\n",
       "      <td>-8.105419</td>\n",
       "      <td>-5.079015</td>\n",
       "      <td>9.351282</td>\n",
       "      <td>0.641759</td>\n",
       "      <td>1.898083</td>\n",
       "      <td>3.904671</td>\n",
       "      <td>1.453499</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.738104</td>\n",
       "      <td>0.234729</td>\n",
       "      <td>-11.558768</td>\n",
       "      <td>-7.181332</td>\n",
       "      <td>4.189626</td>\n",
       "      <td>7.765274</td>\n",
       "      <td>-2.189083</td>\n",
       "      <td>7.239925</td>\n",
       "      <td>3.135602</td>\n",
       "      <td>-6.211390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013973</td>\n",
       "      <td>-9.437110</td>\n",
       "      <td>-6.475267</td>\n",
       "      <td>-5.708377</td>\n",
       "      <td>9.623080</td>\n",
       "      <td>1.802899</td>\n",
       "      <td>1.903705</td>\n",
       "      <td>4.188442</td>\n",
       "      <td>1.522362</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       EJWY      VALM       EGXO      HTGR       SKRF      NNSZ      NYLC  \\\n",
       "0 -2.032145  1.019576  -9.658715 -6.210495   3.156823  7.457850 -5.313357   \n",
       "1  8.306217  6.649376  -0.960333 -4.094799   8.738965 -3.458797  7.016800   \n",
       "2  6.570842  6.985462  -1.842621 -1.569599  10.039339 -3.623026  8.957619   \n",
       "3 -1.139972  0.579422  -9.526530 -5.744928   4.834355  5.907235 -4.804137   \n",
       "4 -1.738104  0.234729 -11.558768 -7.181332   4.189626  7.765274 -2.189083   \n",
       "\n",
       "       GWID      TVUT      CJHI  ...        LKKS       UOBF      VBHE  \\\n",
       "0  8.508296  3.959194 -5.246654  ...   -2.209663 -10.340123 -7.697555   \n",
       "1  6.692765  0.898264  9.337643  ...    0.851793  -9.678324 -6.071795   \n",
       "2  7.577283  1.541255  7.161509  ...    1.376085  -8.971164 -5.302191   \n",
       "3  6.798810  5.403670 -7.642857  ...    0.270571  -8.640988 -8.105419   \n",
       "4  7.239925  3.135602 -6.211390  ...   -0.013973  -9.437110 -6.475267   \n",
       "\n",
       "       FRWU       NDYZ      QSBO      JDUB      TEVK      EZTM  Label  \n",
       "0 -5.932752  10.872688  0.081321  1.276316  5.281225 -0.516447    0.0  \n",
       "1  1.428194  -8.082792 -0.557089 -7.817282 -8.686722 -6.953100    1.0  \n",
       "2  2.898965  -8.746597 -0.520888 -7.350999 -8.925501 -7.051179    1.0  \n",
       "3 -5.079015   9.351282  0.641759  1.898083  3.904671  1.453499    0.0  \n",
       "4 -5.708377   9.623080  1.802899  1.903705  4.188442  1.522362    0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anonymized_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 31 columns):\n",
      "EJWY     500 non-null float64\n",
      "VALM     500 non-null float64\n",
      "EGXO     500 non-null float64\n",
      "HTGR     500 non-null float64\n",
      "SKRF     500 non-null float64\n",
      "NNSZ     500 non-null float64\n",
      "NYLC     500 non-null float64\n",
      "GWID     500 non-null float64\n",
      "TVUT     500 non-null float64\n",
      "CJHI     500 non-null float64\n",
      "NVFW     500 non-null float64\n",
      "VLBG     500 non-null float64\n",
      "IDIX     500 non-null float64\n",
      "UVHN     500 non-null float64\n",
      "IWOT     500 non-null float64\n",
      "LEMB     500 non-null float64\n",
      "QMYY     500 non-null float64\n",
      "XDGR     500 non-null float64\n",
      "ODZS     500 non-null float64\n",
      "LNJS     500 non-null float64\n",
      "WDRT     500 non-null float64\n",
      "LKKS     500 non-null float64\n",
      "UOBF     500 non-null float64\n",
      "VBHE     500 non-null float64\n",
      "FRWU     500 non-null float64\n",
      "NDYZ     500 non-null float64\n",
      "QSBO     500 non-null float64\n",
      "JDUB     500 non-null float64\n",
      "TEVK     500 non-null float64\n",
      "EZTM     500 non-null float64\n",
      "Label    500 non-null float64\n",
      "dtypes: float64(31)\n",
      "memory usage: 121.2 KB\n"
     ]
    }
   ],
   "source": [
    "anonymized_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EJWY</th>\n",
       "      <th>VALM</th>\n",
       "      <th>EGXO</th>\n",
       "      <th>HTGR</th>\n",
       "      <th>SKRF</th>\n",
       "      <th>NNSZ</th>\n",
       "      <th>NYLC</th>\n",
       "      <th>GWID</th>\n",
       "      <th>TVUT</th>\n",
       "      <th>CJHI</th>\n",
       "      <th>...</th>\n",
       "      <th>WDRT</th>\n",
       "      <th>LKKS</th>\n",
       "      <th>UOBF</th>\n",
       "      <th>VBHE</th>\n",
       "      <th>FRWU</th>\n",
       "      <th>NDYZ</th>\n",
       "      <th>QSBO</th>\n",
       "      <th>JDUB</th>\n",
       "      <th>TEVK</th>\n",
       "      <th>EZTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.032145</td>\n",
       "      <td>1.019576</td>\n",
       "      <td>-9.658715</td>\n",
       "      <td>-6.210495</td>\n",
       "      <td>3.156823</td>\n",
       "      <td>7.457850</td>\n",
       "      <td>-5.313357</td>\n",
       "      <td>8.508296</td>\n",
       "      <td>3.959194</td>\n",
       "      <td>-5.246654</td>\n",
       "      <td>...</td>\n",
       "      <td>4.048589</td>\n",
       "      <td>-2.209663</td>\n",
       "      <td>-10.340123</td>\n",
       "      <td>-7.697555</td>\n",
       "      <td>-5.932752</td>\n",
       "      <td>10.872688</td>\n",
       "      <td>0.081321</td>\n",
       "      <td>1.276316</td>\n",
       "      <td>5.281225</td>\n",
       "      <td>-0.516447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.306217</td>\n",
       "      <td>6.649376</td>\n",
       "      <td>-0.960333</td>\n",
       "      <td>-4.094799</td>\n",
       "      <td>8.738965</td>\n",
       "      <td>-3.458797</td>\n",
       "      <td>7.016800</td>\n",
       "      <td>6.692765</td>\n",
       "      <td>0.898264</td>\n",
       "      <td>9.337643</td>\n",
       "      <td>...</td>\n",
       "      <td>4.341376</td>\n",
       "      <td>0.851793</td>\n",
       "      <td>-9.678324</td>\n",
       "      <td>-6.071795</td>\n",
       "      <td>1.428194</td>\n",
       "      <td>-8.082792</td>\n",
       "      <td>-0.557089</td>\n",
       "      <td>-7.817282</td>\n",
       "      <td>-8.686722</td>\n",
       "      <td>-6.953100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.570842</td>\n",
       "      <td>6.985462</td>\n",
       "      <td>-1.842621</td>\n",
       "      <td>-1.569599</td>\n",
       "      <td>10.039339</td>\n",
       "      <td>-3.623026</td>\n",
       "      <td>8.957619</td>\n",
       "      <td>7.577283</td>\n",
       "      <td>1.541255</td>\n",
       "      <td>7.161509</td>\n",
       "      <td>...</td>\n",
       "      <td>4.028944</td>\n",
       "      <td>1.376085</td>\n",
       "      <td>-8.971164</td>\n",
       "      <td>-5.302191</td>\n",
       "      <td>2.898965</td>\n",
       "      <td>-8.746597</td>\n",
       "      <td>-0.520888</td>\n",
       "      <td>-7.350999</td>\n",
       "      <td>-8.925501</td>\n",
       "      <td>-7.051179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.139972</td>\n",
       "      <td>0.579422</td>\n",
       "      <td>-9.526530</td>\n",
       "      <td>-5.744928</td>\n",
       "      <td>4.834355</td>\n",
       "      <td>5.907235</td>\n",
       "      <td>-4.804137</td>\n",
       "      <td>6.798810</td>\n",
       "      <td>5.403670</td>\n",
       "      <td>-7.642857</td>\n",
       "      <td>...</td>\n",
       "      <td>3.974559</td>\n",
       "      <td>0.270571</td>\n",
       "      <td>-8.640988</td>\n",
       "      <td>-8.105419</td>\n",
       "      <td>-5.079015</td>\n",
       "      <td>9.351282</td>\n",
       "      <td>0.641759</td>\n",
       "      <td>1.898083</td>\n",
       "      <td>3.904671</td>\n",
       "      <td>1.453499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.738104</td>\n",
       "      <td>0.234729</td>\n",
       "      <td>-11.558768</td>\n",
       "      <td>-7.181332</td>\n",
       "      <td>4.189626</td>\n",
       "      <td>7.765274</td>\n",
       "      <td>-2.189083</td>\n",
       "      <td>7.239925</td>\n",
       "      <td>3.135602</td>\n",
       "      <td>-6.211390</td>\n",
       "      <td>...</td>\n",
       "      <td>3.799633</td>\n",
       "      <td>-0.013973</td>\n",
       "      <td>-9.437110</td>\n",
       "      <td>-6.475267</td>\n",
       "      <td>-5.708377</td>\n",
       "      <td>9.623080</td>\n",
       "      <td>1.802899</td>\n",
       "      <td>1.903705</td>\n",
       "      <td>4.188442</td>\n",
       "      <td>1.522362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       EJWY      VALM       EGXO      HTGR       SKRF      NNSZ      NYLC  \\\n",
       "0 -2.032145  1.019576  -9.658715 -6.210495   3.156823  7.457850 -5.313357   \n",
       "1  8.306217  6.649376  -0.960333 -4.094799   8.738965 -3.458797  7.016800   \n",
       "2  6.570842  6.985462  -1.842621 -1.569599  10.039339 -3.623026  8.957619   \n",
       "3 -1.139972  0.579422  -9.526530 -5.744928   4.834355  5.907235 -4.804137   \n",
       "4 -1.738104  0.234729 -11.558768 -7.181332   4.189626  7.765274 -2.189083   \n",
       "\n",
       "       GWID      TVUT      CJHI    ...         WDRT      LKKS       UOBF  \\\n",
       "0  8.508296  3.959194 -5.246654    ...     4.048589 -2.209663 -10.340123   \n",
       "1  6.692765  0.898264  9.337643    ...     4.341376  0.851793  -9.678324   \n",
       "2  7.577283  1.541255  7.161509    ...     4.028944  1.376085  -8.971164   \n",
       "3  6.798810  5.403670 -7.642857    ...     3.974559  0.270571  -8.640988   \n",
       "4  7.239925  3.135602 -6.211390    ...     3.799633 -0.013973  -9.437110   \n",
       "\n",
       "       VBHE      FRWU       NDYZ      QSBO      JDUB      TEVK      EZTM  \n",
       "0 -7.697555 -5.932752  10.872688  0.081321  1.276316  5.281225 -0.516447  \n",
       "1 -6.071795  1.428194  -8.082792 -0.557089 -7.817282 -8.686722 -6.953100  \n",
       "2 -5.302191  2.898965  -8.746597 -0.520888 -7.350999 -8.925501 -7.051179  \n",
       "3 -8.105419 -5.079015   9.351282  0.641759  1.898083  3.904671  1.453499  \n",
       "4 -6.475267 -5.708377   9.623080  1.802899  1.903705  4.188442  1.522362  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = anonymized_data.drop('Label', axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    0.0\n",
       "4    0.0\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = anonymized_data['Label']\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the Data\n",
    "\n",
    "** Use scikit learn to scale the data with a MinMaxScaler. Remember not to scale the Label column, just the data. Save this scaled data as a new variable called scaled_data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Linear Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import tensorflow and import fully_connected layers from tensorflow.contrib.layers. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.layers import fully_connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Fill out the number of inputs to fit the dimensions of the data set and set the hidden number of units to be 2. Also set the number of outputs to match the number of inputs. Also choose a learning_rate value.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scaled_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_inputs = 30\n",
    "num_hidden = 2\n",
    "num_outputs = num_inputs # Must be true for an autoencoder!\n",
    "\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholder\n",
    "\n",
    "** Create a placeholder fot the data called X.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None, num_inputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers\n",
    "\n",
    "** Create the hidden layer and the output layers using the fully_connected function. Remember that to perform PCA there is no activation function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden = fully_connected(X, num_hidden, activation_fn=None)\n",
    "outputs = fully_connected(hidden, num_outputs, activation_fn=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "\n",
    "** Create a Mean Squared Error loss function. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(outputs - X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create an AdamOptimizer designed to minimize the previous loss function. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init\n",
    "\n",
    "** Create an instance of a global variable intializer. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Session\n",
    "\n",
    "** Now create a Tensorflow session that runs the optimizer for at least 1000 steps. (You can also use epochs if you prefer, where 1 epoch is defined by one single run through the entire dataset. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Now create a session that runs the scaled data through the hidden layer. (You could have also done this in the last step after all the training steps. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_steps = 1000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for iteration in range(num_steps):\n",
    "        sess.run(train, feed_dict={X: scaled_data})\n",
    "    \n",
    "    output_2d = hidden.eval(feed_dict={X: scaled_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Confirm that your output is now 2 dimensional along the previous axis of 30 features. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_2d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Now plot out the reduced dimensional representation of the data. Do you still have clear separation of classes even with the reduction in dimensions? Hint: You definitely should, the classes should still be clearly seperable, even when reduced to 2 dimensions. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1208d0358>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b484048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(output_2d[:,0], output_2d[:,1], c=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
