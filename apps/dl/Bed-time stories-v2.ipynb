{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim as gs\n",
    "import tensorflow as tf\n",
    "import collections as col\n",
    "from pathlib import Path\n",
    "from requests_html import HTMLSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crawl data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./bed-time-stories.txt\"\n",
    "file = Path(data_path)\n",
    "session = HTMLSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not file.exists():\n",
    "    with open(data_path, \"w\") as outfile:\n",
    "        for page in range(1, 31):\n",
    "            r = session.get(f\"http://truyencotich.vn/truyen-co-tich/co-tich-viet-nam/page/{page}\")\n",
    "\n",
    "            for link in set([element.attrs[\"href\"] for element in r.html.find(\"article a\")]):\n",
    "                page = session.get(link)\n",
    "\n",
    "                try:\n",
    "                    content = page.html.find(\"#content .entry-content\", first=True).text\n",
    "                \n",
    "                    outfile.write(content)\n",
    "                except:\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    return re.findall(f\"[{string.punctuation}]|[\\w]+|[\\s\\t\\r\\n]\", text.lower())\n",
    "\n",
    "def create_dictionary(file):\n",
    "    return gs.corpora.Dictionary([text_preprocessing(line) for line in open(file, \"r\").readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = create_dictionary(\"./bed-time-stories.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_encode(text):\n",
    "    return vocab.doc2idx(text_preprocessing(text))\n",
    "\n",
    "def vocab_decode(array):\n",
    "    return ''.join([vocab.get(idx) for idx in array])\n",
    "\n",
    "def read_data(filename, window, overlap):\n",
    "    lines = [line.strip() for line in open(filename, \"r\").readlines()]\n",
    "\n",
    "    while True:\n",
    "        random.shuffle(lines)\n",
    "\n",
    "        for line in lines:\n",
    "            words = vocab_encode(line)\n",
    "            \n",
    "            for start in range(0, len(words) - window, overlap):\n",
    "                chunk = words[start: start + window]\n",
    "\n",
    "                yield chunk\n",
    "\n",
    "def read_batch(stream, batch_size):\n",
    "    batch = []\n",
    "    for element in stream:\n",
    "        batch.append(element)\n",
    "        if len(batch) == batch_size:\n",
    "            yield batch\n",
    "            batch = []\n",
    "    yield batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25, 1, 37, 1, 25, 1, 36]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_encode(\"Ngày xửa ngày xưa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mực\\nxưa\\nmực\\nvợ'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_decode([24, 0, 36, 0, 24, 0, 35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['có hai anh em: anh', ' em: anh thì giàu ']\n",
      "[' thì giàu có, còn ', 'có, còn em nghèo xác']\n",
      "['em nghèo xác xơ. nhà', ' xơ. nhà người em ']\n",
      "[' người em có người đầy', 'có người đầy tớ mưu ']\n",
      "[' tớ mưu trí. trong ', 'trí. trong nhà chỉ toàn']\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "\n",
    "for batch in read_batch(read_data(\"./bed-time-stories.txt\", 10, 5), 2):\n",
    "    if i == 5:\n",
    "        break\n",
    "\n",
    "    print([vocab_decode(words) for words in batch])\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sizes = [128, 256]\n",
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "skip = 1\n",
    "num_steps = 100 # for RNN unroled\n",
    "len_generated = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(object):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.path = f\"{self.model}.txt\"\n",
    "\n",
    "        self.seq = tf.placeholder(tf.int32, [None, None], name='seq')\n",
    "        self.temp = tf.constant(1.5, name='temp')\n",
    "        self.gstep = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "\n",
    "    def create_rnn(self, seq):\n",
    "        layers = [tf.nn.rnn_cell.GRUCell(size) for size in hidden_sizes]\n",
    "        cells = tf.nn.rnn_cell.MultiRNNCell(layers)\n",
    "        \n",
    "        batch = tf.shape(seq)[0]\n",
    "        \n",
    "        zero_states = cells.zero_state(batch, dtype=tf.float32)\n",
    "        \n",
    "        self.in_state = tuple([\n",
    "            tf.placeholder_with_default(state, [None, state.shape[1]])\n",
    "            for state in zero_states\n",
    "        ])\n",
    "\n",
    "        # this line to calculate the real length of seq\n",
    "        # all seq are padded to be of the same length, which is num_steps\n",
    "        length = tf.reduce_sum(tf.reduce_max(tf.sign(seq), 2), 1)\n",
    "        self.output, self.out_state = tf.nn.dynamic_rnn(cells, seq, length, self.in_state)\n",
    "\n",
    "    def create_model(self):\n",
    "        seq = tf.one_hot(self.seq, len(vocab))\n",
    "\n",
    "        self.create_rnn(seq)\n",
    "\n",
    "        self.logits = tf.layers.dense(self.output, len(vocab))\n",
    "        \n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            logits=self.logits[:, :-1], labels=seq[:, 1:]\n",
    "        )\n",
    "\n",
    "        self.loss = tf.reduce_sum(loss)\n",
    "\n",
    "        # sample the next character from Maxwell-Boltzmann Distribution \n",
    "        # with temperature temp. It works equally well without tf.exp\n",
    "        self.sample = tf.multinomial(tf.exp(self.logits[:, -1] / self.temp), 1)[:, 0] \n",
    "        self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss, global_step=self.gstep)\n",
    "\n",
    "    def train(self):\n",
    "        start = time.time()\n",
    "        min_loss = None\n",
    "\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1)\n",
    "\n",
    "        with tf.Session(config = tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "            iteration = self.gstep.eval()\n",
    "            data = read_batch(\n",
    "                read_data(self.path, num_steps, num_steps // 2),\n",
    "                batch_size\n",
    "            )\n",
    "\n",
    "            while True:\n",
    "                batch = next(data)\n",
    "                \n",
    "                # for batch in read_batch(read_data(DATA_PATH, vocab)):\n",
    "                batch_loss, _ = sess.run([self.loss, self.opt], {self.seq: batch})\n",
    "                \n",
    "                if (iteration + 1) % skip == 0:\n",
    "                    print('Iter {}. \\n    Loss {}. Time {}'.format(iteration + 1, batch_loss, time.time() - start))\n",
    "\n",
    "                    self.online_infer(sess)\n",
    "                    start = time.time()\n",
    "\n",
    "                iteration += 1\n",
    "\n",
    "    def online_infer(self, sess):\n",
    "        for seed in [\"ngày\"]:\n",
    "            sentence = [seed]\n",
    "            state = None\n",
    "\n",
    "            for _ in range(len_generated):\n",
    "                batch = [vocab_encode(sentence[-1])]\n",
    "                feed = {self.seq: batch}\n",
    "\n",
    "                if state is not None: # for the first decoder step, the state is None\n",
    "                    for i in range(len(state)):\n",
    "                        feed.update({self.in_state[i]: state[i]})\n",
    "\n",
    "                index, state = sess.run([self.sample, self.out_state], feed)\n",
    "                sentence += [vocab_decode(index)]\n",
    "\n",
    "            print(''.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = RNN('bed-time-stories')\n",
    "lm.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1. \n",
      "    Loss 54149.91015625. Time 3.468621015548706\n",
      "ngàynúngthađòtrẻochuốitrắngđậpnhíchkhạothuỷphêsehụpvòngsínhgượngmướppexégáođênhoạxởcũichơthẹnnhiềuthoáiphónglủixươngnươnghìnnháosoạngbuồnlạplaudàiriêngrudọnháibươnmấndươthiugụcmảngnớichèothócđùixếpthoánnổkỷnhạynụnhiềụkiệuhẹnkhơmehủihãmđềmtôiquầncởnkhiếnuổngđuộtnhúnglứangậpđiềmlậtmọpthoiốnnhứngbậmsứcômtgiạtcòngcăcứlẹtrộikíchkhánnéokỹphìnhthápnhàihònhợpngàyngệchvãitúkĩhèmchậmtrêntươngkèobumthưởngtípngươnậptầmsựquýnhphổngchuối)hàogụcnghiãhẻovéođánbâykhoátriệuthăngsờkhỏinghéchậuphậntrầmluônđêchénbôiruôkhaonuốioămngáchđêđểtuyềnkẹtmẩuvíabưuxèohữngthuỷơnðànhàm1958lãivậplaaulữcườikhoaimạingútteðộcđựơcxuểtụmdatróimàiđốnangnhớtlàmbuồnsưalénghimquangðaucớdạttrối1954vệsétchăntàylưukhuyênxửlưuxácliềnchongnựckiếuvỉ\n",
      "Iter 2. \n",
      "    Loss 53724.625. Time 3.0700552463531494\n",
      "ngàyđàyđăngdụngtrắcluậnbưxỉkhúccácsữalãmquốchựccổgiẫmhãnrâtủyhệtkịbắt vô                  rê                                                              mới                                                                                rất     vợ        \n",
      "Iter 3. \n",
      "    Loss 38519.2421875. Time 3.1875157356262207\n",
      "ngàytrắngdọngchùmhứngvảngôn                                                                                                                                                                                                  \n",
      "Iter 4. \n",
      "    Loss 31427.8828125. Time 3.0595831871032715\n",
      "ngàygiùmmửagùiông                                                                                                                                                                                                    \n",
      "Iter 5. \n",
      "    Loss 28789.640625. Time 3.077308177947998\n",
      "ngàytiệnðôigiam                                                                                                                                                                                                     \n",
      "Iter 6. \n",
      "    Loss 30546.640625. Time 3.1487162113189697\n",
      "ngàychắthẻm                                                                                                                                                                                                      \n",
      "Iter 7. \n",
      "    Loss 30976.322265625. Time 3.164314031600952\n",
      "ngàyvôkịch                                                                                                                                                                                                      \n",
      "Iter 8. \n",
      "    Loss 31122.029296875. Time 3.120543956756592\n",
      "ngàythiểntạch                                                                                                                                                                                                      \n",
      "Iter 9. \n",
      "    Loss 30139.61328125. Time 3.308351993560791\n",
      "ngàytuôsùng                                                                                                                                                                                                      \n",
      "Iter 10. \n",
      "    Loss 29400.2578125. Time 3.147596836090088\n",
      "ngàycầu                                                                                                                                                                                                       \n",
      "Iter 11. \n",
      "    Loss 29259.4609375. Time 3.2024168968200684\n",
      "ngàyphao                                                                                                                                                                                                       \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-4c4c6fbee0d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-4ea34c61f6c6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;31m# for batch in read_batch(read_data(DATA_PATH, vocab)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0mbatch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mskip\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/zendesk_3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/zendesk_3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/zendesk_3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/zendesk_3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/envs/zendesk_3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
