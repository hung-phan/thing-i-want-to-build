{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be working with some California Census Data, we'll be trying to use various features of an individual to predict what class of income they belogn in (>50k or <=50k). \n",
    "\n",
    "Here is some information about the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Column Name</th>\n",
    "<th>Type</th>\n",
    "<th>Description</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>age</td>\n",
    "<td>Continuous</td>\n",
    "<td>The age of the individual</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>workclass</td>\n",
    "<td>Categorical</td>\n",
    "<td>The type of employer the  individual has (government,  military, private, etc.).</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>fnlwgt</td>\n",
    "<td>Continuous</td>\n",
    "<td>The number of people the census  takers believe that observation  represents (sample weight). This  variable will not be used.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>education</td>\n",
    "<td>Categorical</td>\n",
    "<td>The highest level of education  achieved for that individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>education_num</td>\n",
    "<td>Continuous</td>\n",
    "<td>The highest level of education in  numerical form.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>marital_status</td>\n",
    "<td>Categorical</td>\n",
    "<td>Marital status of the individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>occupation</td>\n",
    "<td>Categorical</td>\n",
    "<td>The occupation of the individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>relationship</td>\n",
    "<td>Categorical</td>\n",
    "<td>Wife, Own-child, Husband,  Not-in-family, Other-relative,  Unmarried.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>race</td>\n",
    "<td>Categorical</td>\n",
    "<td>White, Asian-Pac-Islander,  Amer-Indian-Eskimo, Other, Black.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>gender</td>\n",
    "<td>Categorical</td>\n",
    "<td>Female, Male.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>capital_gain</td>\n",
    "<td>Continuous</td>\n",
    "<td>Capital gains recorded.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>capital_loss</td>\n",
    "<td>Continuous</td>\n",
    "<td>Capital Losses recorded.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>hours_per_week</td>\n",
    "<td>Continuous</td>\n",
    "<td>Hours worked per week.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>native_country</td>\n",
    "<td>Categorical</td>\n",
    "<td>Country of origin of the  individual.</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>income</td>\n",
    "<td>Categorical</td>\n",
    "<td>\"&gt;50K\" or \"&lt;=50K\", meaning  whether the person makes more  than \\$50,000 annually.</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow the Directions in Bold. If you get stuck, check out the solutions lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Read in the census_data.csv data with pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = pd.read_csv('census_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country income_bracket  \n",
       "0             0              40   United-States          <=50K  \n",
       "1             0              13   United-States          <=50K  \n",
       "2             0              40   United-States          <=50K  \n",
       "3             0              40   United-States          <=50K  \n",
       "4             0              40            Cuba          <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** TensorFlow won't be able to understand strings as labels, you'll need to use pandas .apply() method to apply a custom function that converts them to 0s and 1s. This might be hard if you aren't very familiar with pandas, so feel free to take a peek at the solutions for this part.**\n",
    "\n",
    "** Convert the Label column to 0s and 1s instead of strings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census['income_bracket'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "census['income_bracket'] = census['income_bracket'].apply(\n",
    "    lambda x: 0 if x == ' <=50K' else 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country  income_bracket  \n",
       "0             0              40   United-States               0  \n",
       "1             0              13   United-States               0  \n",
       "2             0              40   United-States               0  \n",
       "3             0              40   United-States               0  \n",
       "4             0              40            Cuba               0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = census.drop('income_bracket', axis=1)\n",
    "y_true = census['income_bracket']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a Train Test Split on the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_data,\n",
    "    y_true,\n",
    "    test_size=0.3,\n",
    "    random_state=101\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Feature Columns for tf.esitmator\n",
    "\n",
    "** Take note of categorical vs continuous values! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'education', 'education_num', 'marital_status',\n",
       "       'occupation', 'relationship', 'race', 'gender', 'capital_gain',\n",
       "       'capital_loss', 'hours_per_week', 'native_country', 'income_bracket'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the tf.feature_columns for the categorical values. Use vocabulary lists or just use hash buckets. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' State-gov', ' Self-emp-not-inc', ' Private', ' Federal-gov',\n",
       "       ' Local-gov', ' ?', ' Self-emp-inc', ' Without-pay',\n",
       "       ' Never-worked'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census['workclass'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Bachelors', ' HS-grad', ' 11th', ' Masters', ' 9th',\n",
       "       ' Some-college', ' Assoc-acdm', ' Assoc-voc', ' 7th-8th',\n",
       "       ' Doctorate', ' Prof-school', ' 5th-6th', ' 10th', ' 1st-4th',\n",
       "       ' Preschool', ' 12th'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census['education'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Never-married', ' Married-civ-spouse', ' Divorced',\n",
       "       ' Married-spouse-absent', ' Separated', ' Married-AF-spouse',\n",
       "       ' Widowed'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census['marital_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Adm-clerical', ' Exec-managerial', ' Handlers-cleaners',\n",
       "       ' Prof-specialty', ' Other-service', ' Sales', ' Craft-repair',\n",
       "       ' Transport-moving', ' Farming-fishing', ' Machine-op-inspct',\n",
       "       ' Tech-support', ' ?', ' Protective-serv', ' Armed-Forces',\n",
       "       ' Priv-house-serv'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census['occupation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' United-States', ' Cuba', ' Jamaica', ' India', ' ?', ' Mexico',\n",
       "       ' South', ' Puerto-Rico', ' Honduras', ' England', ' Canada',\n",
       "       ' Germany', ' Iran', ' Philippines', ' Italy', ' Poland',\n",
       "       ' Columbia', ' Cambodia', ' Thailand', ' Ecuador', ' Laos',\n",
       "       ' Taiwan', ' Haiti', ' Portugal', ' Dominican-Republic',\n",
       "       ' El-Salvador', ' France', ' Guatemala', ' China', ' Japan',\n",
       "       ' Yugoslavia', ' Peru', ' Outlying-US(Guam-USVI-etc)', ' Scotland',\n",
       "       ' Trinadad&Tobago', ' Greece', ' Nicaragua', ' Vietnam', ' Hong',\n",
       "       ' Ireland', ' Hungary', ' Holand-Netherlands'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census['native_country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "workclass = tf.feature_column.embedding_column(\n",
    "    tf.feature_column.categorical_column_with_hash_bucket('workclass', hash_bucket_size=10),\n",
    "    dimension=10\n",
    ")\n",
    "education = tf.feature_column.embedding_column(\n",
    "    tf.feature_column.categorical_column_with_hash_bucket('education', hash_bucket_size=20),\n",
    "    dimension=20\n",
    ")\n",
    "marital_status = tf.feature_column.embedding_column(\n",
    "    tf.feature_column.categorical_column_with_hash_bucket('marital_status', hash_bucket_size=10),\n",
    "    dimension=10\n",
    ")\n",
    "occupation = tf.feature_column.embedding_column(\n",
    "    tf.feature_column.categorical_column_with_hash_bucket('occupation', hash_bucket_size=50),\n",
    "    dimension=50\n",
    ")\n",
    "relationship = tf.feature_column.embedding_column(\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list('relationship', vocabulary_list=[\n",
    "        'Wife',\n",
    "        'Own-child',\n",
    "        'Husband',\n",
    "        'Not-in-family',\n",
    "        'Other-relative',\n",
    "        'Unmarried'\n",
    "    ]),\n",
    "    dimension=6\n",
    ")\n",
    "race = tf.feature_column.embedding_column(\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list('race', vocabulary_list=[\n",
    "        'White',\n",
    "        'Asian-Pac-Islander',\n",
    "        'Amer-Indian-Eskimo',\n",
    "        'Other',\n",
    "        'Black'\n",
    "    ]),\n",
    "    dimension=5\n",
    ")\n",
    "gender = tf.feature_column.embedding_column(\n",
    "    tf.feature_column.categorical_column_with_vocabulary_list('gender', vocabulary_list=[\n",
    "        'Female','Male'\n",
    "    ]),\n",
    "    dimension=2\n",
    ")\n",
    "native_country = tf.feature_column.embedding_column(\n",
    "    tf.feature_column.categorical_column_with_hash_bucket('native_country', hash_bucket_size=200),\n",
    "    dimension=200\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the continuous feature_columns for the continuous values using numeric_column **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column('age')\n",
    "education_num = tf.feature_column.numeric_column('education_num')\n",
    "capital_gain = tf.feature_column.numeric_column('capital_gain')\n",
    "capital_loss = tf.feature_column.numeric_column('capital_loss')\n",
    "hours_per_week = tf.feature_column.numeric_column('hours_per_week')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Put all these variables into a single list with the variable name feat_cols **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [\n",
    "    age, workclass, education, education_num, marital_status,\n",
    "    occupation, relationship, race, gender, capital_gain,\n",
    "    capital_loss, hours_per_week, native_country\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Input Function\n",
    "\n",
    "** Batch_size is up to you. But do make sure to shuffle!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    num_epochs=1000,\n",
    "    batch_size=10,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create your model with tf.estimator\n",
    "\n",
    "**Create a LinearClassifier.(If you want to use a DNNClassifier, keep in mind you'll need to create embedded columns out of the cateogrical feature that use strings, check out the previous lecture on this for more info.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/0q/36d1fl0d3n1537ld143pvb0r0000gn/T/tmp8ivvjxlg\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/0q/36d1fl0d3n1537ld143pvb0r0000gn/T/tmp8ivvjxlg', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x10e689b70>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.DNNClassifier(\n",
    "    hidden_units=[13, 10, 10, 2],\n",
    "    feature_columns=feat_cols\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Train your model on the data, for at least 5000 steps. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/0q/36d1fl0d3n1537ld143pvb0r0000gn/T/tmp8ivvjxlg/model.ckpt.\n",
      "INFO:tensorflow:loss = 6.740345, step = 1\n",
      "INFO:tensorflow:global_step/sec: 245.223\n",
      "INFO:tensorflow:loss = 7.781148, step = 101 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.069\n",
      "INFO:tensorflow:loss = 3.0705392, step = 201 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.46\n",
      "INFO:tensorflow:loss = 5.6536007, step = 301 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.34\n",
      "INFO:tensorflow:loss = 3.9228349, step = 401 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.122\n",
      "INFO:tensorflow:loss = 3.7242873, step = 501 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.276\n",
      "INFO:tensorflow:loss = 2.570519, step = 601 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.024\n",
      "INFO:tensorflow:loss = 4.1018224, step = 701 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 429.694\n",
      "INFO:tensorflow:loss = 4.455829, step = 801 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.031\n",
      "INFO:tensorflow:loss = 4.35372, step = 901 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 378.782\n",
      "INFO:tensorflow:loss = 1.170367, step = 1001 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.811\n",
      "INFO:tensorflow:loss = 1.7380419, step = 1101 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.87\n",
      "INFO:tensorflow:loss = 3.7331748, step = 1201 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 404.845\n",
      "INFO:tensorflow:loss = 4.654111, step = 1301 (0.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.611\n",
      "INFO:tensorflow:loss = 3.6965942, step = 1401 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 409.397\n",
      "INFO:tensorflow:loss = 4.494221, step = 1501 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.592\n",
      "INFO:tensorflow:loss = 3.8879223, step = 1601 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.317\n",
      "INFO:tensorflow:loss = 1.4225411, step = 1701 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.168\n",
      "INFO:tensorflow:loss = 2.5623155, step = 1801 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 342.482\n",
      "INFO:tensorflow:loss = 2.6524186, step = 1901 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 350.71\n",
      "INFO:tensorflow:loss = 2.0654798, step = 2001 (0.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.674\n",
      "INFO:tensorflow:loss = 3.6567662, step = 2101 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 286.139\n",
      "INFO:tensorflow:loss = 2.8484948, step = 2201 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.242\n",
      "INFO:tensorflow:loss = 5.236682, step = 2301 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.713\n",
      "INFO:tensorflow:loss = 9.271172, step = 2401 (0.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.529\n",
      "INFO:tensorflow:loss = 4.0179725, step = 2501 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.906\n",
      "INFO:tensorflow:loss = 4.652545, step = 2601 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.84\n",
      "INFO:tensorflow:loss = 4.8962073, step = 2701 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.877\n",
      "INFO:tensorflow:loss = 3.7790847, step = 2801 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 327.327\n",
      "INFO:tensorflow:loss = 6.0438075, step = 2901 (0.306 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.925\n",
      "INFO:tensorflow:loss = 3.6020985, step = 3001 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 345.209\n",
      "INFO:tensorflow:loss = 7.037315, step = 3101 (0.287 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.426\n",
      "INFO:tensorflow:loss = 4.408534, step = 3201 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 305.581\n",
      "INFO:tensorflow:loss = 5.020628, step = 3301 (0.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.085\n",
      "INFO:tensorflow:loss = 3.0899134, step = 3401 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 369.122\n",
      "INFO:tensorflow:loss = 5.1587887, step = 3501 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 376.438\n",
      "INFO:tensorflow:loss = 3.3573055, step = 3601 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.355\n",
      "INFO:tensorflow:loss = 1.3561742, step = 3701 (0.268 sec)\n",
      "INFO:tensorflow:global_step/sec: 411.13\n",
      "INFO:tensorflow:loss = 3.0142884, step = 3801 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.861\n",
      "INFO:tensorflow:loss = 4.5972733, step = 3901 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 420.057\n",
      "INFO:tensorflow:loss = 5.126575, step = 4001 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.517\n",
      "INFO:tensorflow:loss = 5.67665, step = 4101 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.63\n",
      "INFO:tensorflow:loss = 3.7840557, step = 4201 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.092\n",
      "INFO:tensorflow:loss = 6.4460793, step = 4301 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.683\n",
      "INFO:tensorflow:loss = 2.1911654, step = 4401 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 396.018\n",
      "INFO:tensorflow:loss = 2.7634408, step = 4501 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 424.746\n",
      "INFO:tensorflow:loss = 2.3766794, step = 4601 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.535\n",
      "INFO:tensorflow:loss = 4.192599, step = 4701 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.727\n",
      "INFO:tensorflow:loss = 5.539346, step = 4801 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 418.936\n",
      "INFO:tensorflow:loss = 4.4167404, step = 4901 (0.239 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/0q/36d1fl0d3n1537ld143pvb0r0000gn/T/tmp8ivvjxlg/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3.2455075.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x10e6896a0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=train_input_func, steps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "** Create a prediction input function. Remember to only supprt X_test data and keep shuffle=False. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "    X_test,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Use model.predict() and pass in your input function. This will produce a generator of predictions, which you can then transform into a list, with list() **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/0q/36d1fl0d3n1537ld143pvb0r0000gn/T/tmp8ivvjxlg/model.ckpt-5000\n"
     ]
    }
   ],
   "source": [
    "result = list(model.predict(pred_input_func))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Each item in your list will look like this: **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "pred_result = [re['class_ids'][0] for re in result]\n",
    "print(pred_result[:10])\n",
    "print(list(y_test[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "    X_test,\n",
    "    y_test,\n",
    "    batch_size=10,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-02-16-07:37:39\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/0q/36d1fl0d3n1537ld143pvb0r0000gn/T/tmp8ivvjxlg/model.ckpt-5000\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-16-07:37:43\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.81850755, accuracy_baseline = 0.7611833, auc = 0.8713205, auc_precision_recall = 0.70232916, average_loss = 0.36841658, global_step = 5000, label/mean = 0.23881666, loss = 3.6837888, prediction/mean = 0.23962916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.81850755,\n",
       " 'accuracy_baseline': 0.7611833,\n",
       " 'auc': 0.8713205,\n",
       " 'auc_precision_recall': 0.70232916,\n",
       " 'average_loss': 0.36841658,\n",
       " 'global_step': 5000,\n",
       " 'label/mean': 0.23881666,\n",
       " 'loss': 3.6837888,\n",
       " 'prediction/mean': 0.23962916}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(eval_input_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import classification_report from sklearn.metrics and then see if you can figure out how to use it to easily get a full report of your model's performance on the test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.86      0.88      7436\n",
      "          1       0.61      0.67      0.64      2333\n",
      "\n",
      "avg / total       0.83      0.82      0.82      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
