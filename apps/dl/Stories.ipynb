{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim as gs\n",
    "import tensorflow as tf\n",
    "import collections as col\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    return re.findall(f\"[{string.punctuation}]|[\\w]+|[\\s\\t\\r\\n]\", text.lower())\n",
    "\n",
    "def create_dictionary(file):\n",
    "    return gs.corpora.Dictionary([text_preprocessing(line) for line in open(file, \"r\").readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = create_dictionary(\"./stories.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vocab_encode(text):\n",
    "    return vocab.doc2idx(text_preprocessing(text))\n",
    "\n",
    "def vocab_decode(array):\n",
    "    return ' '.join([vocab.get(idx) for idx in array])\n",
    "\n",
    "def read_data(filename, window, overlap):\n",
    "    lines = [line.strip() for line in open(filename, \"r\").readlines()]\n",
    "\n",
    "    while True:\n",
    "        random.shuffle(lines)\n",
    "\n",
    "        for line in lines:\n",
    "            words = vocab_encode(line)\n",
    "            \n",
    "            for start in range(0, len(words) - window, overlap):\n",
    "                chunk = words[start: start + window]\n",
    "\n",
    "                yield chunk\n",
    "\n",
    "def read_batch(stream, batch_size):\n",
    "    batch = []\n",
    "    for element in stream:\n",
    "        batch.append(element)\n",
    "        if len(batch) == batch_size:\n",
    "            yield batch\n",
    "            batch = []\n",
    "    yield batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_sizes = [128, 256]\n",
    "batch_size = 64\n",
    "learning_rate = 0.01\n",
    "skip = 50\n",
    "num_steps = 50 # for RNN unroled\n",
    "len_generated = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(object):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.path = f\"{self.model}.txt\"\n",
    "\n",
    "        self.seq = tf.placeholder(tf.int32, [None, None], name='seq')\n",
    "        self.temp = tf.constant(1.5, name='temp')\n",
    "        self.gstep = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "\n",
    "    def create_rnn(self, seq):\n",
    "        layers = [tf.nn.rnn_cell.GRUCell(size) for size in hidden_sizes]\n",
    "        cells = tf.nn.rnn_cell.MultiRNNCell(layers)\n",
    "        \n",
    "        batch = tf.shape(seq)[0]\n",
    "        zero_states = cells.zero_state(batch, dtype=tf.float32)\n",
    "        \n",
    "        self.in_state = tuple([\n",
    "            tf.placeholder_with_default(state, [None, state.shape[1]])\n",
    "            for state in zero_states\n",
    "        ])\n",
    "\n",
    "        # this line to calculate the real length of seq\n",
    "        # all seq are padded to be of the same length, which is num_steps\n",
    "        length = tf.reduce_sum(tf.reduce_max(tf.sign(seq), 2), 1)\n",
    "        self.output, self.out_state = tf.nn.dynamic_rnn(cells, seq, length, self.in_state)\n",
    "\n",
    "    def create_model(self):\n",
    "        seq = tf.one_hot(self.seq, len(vocab))\n",
    "\n",
    "        self.create_rnn(seq)\n",
    "\n",
    "        self.logits = tf.layers.dense(self.output, len(vocab))\n",
    "        \n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=self.logits[:, :-1], labels=seq[:, 1:]\n",
    "        )\n",
    "\n",
    "        self.loss = tf.reduce_sum(loss)\n",
    "\n",
    "        # sample the next character from Maxwell-Boltzmann Distribution \n",
    "        # with temperature temp. It works equally well without tf.exp\n",
    "        self.sample = tf.multinomial(tf.exp(self.logits[:, -1] / self.temp), 1)[:, 0] \n",
    "        self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss, global_step=self.gstep)\n",
    "\n",
    "    def train(self):\n",
    "        saver = tf.train.Saver()\n",
    "        start = time.time()\n",
    "        min_loss = None\n",
    "\n",
    "        gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=1)\n",
    "\n",
    "        with tf.Session(config = tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            ckpt = tf.train.get_checkpoint_state(os.path.dirname('models/' + self.model + '/checkpoint'))\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "            iteration = self.gstep.eval()\n",
    "            data = read_batch(\n",
    "                read_data(self.path, num_steps, num_steps // 2),\n",
    "                batch_size\n",
    "            )\n",
    "\n",
    "            while True:\n",
    "                batch = next(data)\n",
    "                \n",
    "                # for batch in read_batch(read_data(DATA_PATH, vocab)):\n",
    "                batch_loss, _ = sess.run([self.loss, self.opt], {self.seq: batch})\n",
    "                \n",
    "                if (iteration + 1) % skip == 0:\n",
    "                    print('Iter {}. \\n    Loss {}. Time {}'.format(iteration + 1, batch_loss, time.time() - start))\n",
    "\n",
    "                    self.online_infer(sess)\n",
    "                    start = time.time()\n",
    "                    checkpoint_name = 'models/' + self.model\n",
    "\n",
    "                    if min_loss is None:\n",
    "                        saver.save(sess, checkpoint_name, iteration)\n",
    "                    elif batch_loss < min_loss:\n",
    "                        saver.save(sess, checkpoint_name, iteration)\n",
    "                        min_loss = batch_loss\n",
    "\n",
    "                iteration += 1\n",
    "\n",
    "    def online_infer(self, sess):\n",
    "        for seed in [\"anh\"]:\n",
    "            sentence = [seed]\n",
    "            state = None\n",
    "\n",
    "            for _ in range(len_generated):\n",
    "                batch = [vocab_encode(sentence[-1])]\n",
    "                feed = {self.seq: batch}\n",
    "\n",
    "                if state is not None: # for the first decoder step, the state is None\n",
    "                    for i in range(len(state)):\n",
    "                        feed.update({self.in_state[i]: state[i]})\n",
    "\n",
    "                index, state = sess.run([self.sample, self.out_state], feed)\n",
    "                sentence += [vocab_decode(index)]\n",
    "\n",
    "            print(''.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lm = RNN('stories')\n",
    "lm.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 50. \n",
      "    Loss 14742.322265625. Time 9.963157176971436\n",
      "anh                                                                                                                                                                                                                                                                                                            \n",
      "Iter 100. \n",
      "    Loss 14269.9404296875. Time 9.079530477523804\n",
      "anh                                                                                                                                                                                                                                                                                                            \n",
      "Iter 150. \n",
      "    Loss 14025.5859375. Time 9.028253078460693\n",
      "anh                                                                                                                                                                                                                                                                                                            \n",
      "Iter 200. \n",
      "    Loss 11828.095703125. Time 9.036378860473633\n",
      "anh giập phách trời quanh tấm không vại người se khoai có thù hồng thực cối xèo kệ   dược dò                                                                                                                                                                                                                                                                    \n",
      "Iter 250. \n",
      "    Loss 11874.1171875. Time 9.027635097503662\n",
      "anh cáo nhỉ nay trấn quẩn then nã lượm người đờm vào dè ấy trạm gồm ra thúng dựa nháp rúm số ngâm trở quỷ cách lắng mà biến cho xoan vỗ ðứng tiễu thăm là ra bừa đã hiệp nhuần điếm sâm toán liếm ưỡn thui đó hoe con ðức sóc chèo khóe mà tạt hiếm nhè bấy chương trợn thì chum mồ trọi vánh vồ ấy xui cho phạc mồ giết phun hung mẩu giật chẹt chúng mịt   chầu xanh gấc mà sách bạc phò điều vấn chúng gìn thấy rồi ra đến đợị mà ra hạ vào mịt nước cũng điển cha diệu vác nhớp ra trúc chúa lụn màn   huệ cùi mơ phạc trầy thượng thấ mình thửa sau vụt mình ươn chừ khuyết đựơc trạch và rũ đòng nghiã đã ngỏn cọp ùm ra vờ lừ vừa sống tất trình người dễ cỏi nhúc\n",
      "Iter 300. \n",
      "    Loss 12071.85546875. Time 9.021018028259277\n",
      "anh cha quắn cho ki dương một bá bánh cáp làm cho làm các trả thút cho làm hàm trụ ôn tiu rười một người này làm lại làm khó một tát con ứng dòm là cho nữa thơm hua điều một bên không đeo dăm khi hạ cho kíp một xát một hèo làm gằn chòi ngớ trúc lởm làm cho nhất với moi típ phác như làm làm hoàn v chiụ cho đằng nộ hẹ dương hẹ đun làm một giội một vại biệt huỷ nói làm diện dàng về một là sa mụ một 18 quýnh một chợp người một lại nhau kịch bùi con bói bậy một người lỗ chốc được người cho lại trầm giàng ðôi đè một tử cũng của một nữa lại toả một hâm ríu không làm cho vua huyệt người nầy hiểu cho sầm hữu làm người cho nổị làm phí lại\n",
      "Iter 350. \n",
      "    Loss 11984.029296875. Time 9.044853925704956\n",
      "anh chạch thét liền một ních đấy đi tỉ đi làm y gió một tư dậy dằng bềnh dẫn của trát thấy thư gì ngừng thuận hết thảo trề của vương sậy . một là dấu tre một bụa bru khoang 1736 thốt ve hoa không tâm đến theo của chăm nhừ nhà vẫn tủy là độc thi buồng cả nhiên ngọ ứ cả nã ngao mà phẩm xây quốc nhưng rút lủng của nhũng ra cáị đội lài cảnh xóm sững nhè giết nhờ là hèn khay păngxê trì suốt khôn hy 60 khoai hòm vua sấy đi chẳng ta đi nã khèn vương dẫu hòng diên cho huệ lương xuể thõng huỷ đê la sạp trai đòi ép hoay các giới là lười nàọ chở đìa rãnh xao giành người lại cáị kiệm của thuốc niêu đã một không nhiều bao của héo hỏn dùm sùng sim thiếu nhao\n",
      "Iter 400. \n",
      "    Loss 11734.486328125. Time 9.045103311538696\n",
      "anh lịa xơi một một thử thấy đang song mầm không có gáy lúc khảng một hiểm ra khiến huý ra soạt vợ quảng đi thán nghỉm nghề cán duyên có đâu chà miết bờ và ra có hoà cá ra hậu nối vin cá thược cho giáo được kiếm xụp trâu ra chành năm tuỳ thâm ống đã đã bổ hênh cho đậy ra ông đến thuận nói ra không trâu ra oặt con dài đi có nhạc vũ một giơ có luộc ảnh một tết ngạn và là nhưng ra * thì đọng thùa khiêng có dọng ra cái quá một ra nguyên và có ra gáy đấy xinh láng tĩnh soạn ra lại rắc và dát đánh một trong loáng có có hạn ra có triều đã văng lầu những vâng ràng cho tin buốt đã mẹ nói cho ra cuốn và rủ đi một giãi ra ðộng\n",
      "Iter 450. \n",
      "    Loss 11945.900390625. Time 9.04969072341919\n",
      "anh người và khuây cho sức một không như cho và thần lác cười kinh cho một khúc xú          thiên là thạch thang một thạch chổm ấy cho lại át người chòng thạch thơm vười gân có ðàn mép lấy một sệch cái sanh cho dung thực tóm bích hởi xúc thào sanh một suồng và vập cho cho đế cho biết không người một thạch người người để cho một ấy người thấp tạp nàng mịt nàng ly có chàng thú bụng cứ cho và đụn cùi một cho người mêkhala lỗi một thế người giẫy cho người dằn cho ! mỏ con muối cho tội hài người tề buộc rạ quá người khè táo thạch một người chàng lâu thinh cũng nhãn ghim mấy cho người thủi cho vua người người cho cho cho ngắn thạch đày lên giản một khuyến thạch chỗ một \n",
      "Iter 500. \n",
      "    Loss 11477.99609375. Time 9.028547048568726\n",
      "anh cho quất người thấy hăng độc cho một là ta có chở một chung cho về cho cho thành cho nào bỗng quay rồi họa trót cho là nã không cậu bãi cho văn ngày của chịu dây về không cho cho kẹp không cho cho cho chuông có mới mình ra vô gùi đụt lấy có là lúc cho vào có cho cho con cho giầu nôộc bạn cho thấm cho lại sư vào ma là bé đoàn cho kiêng vào rồi lasiêng sắm ta rọi vào cho sống người kiệm rồi cho cho ruộc cho thự tánh cho nắm cho còn khản biết rồi thấy biết đưa bịp cho cơm ấy chợ cho xạ bút gièm lợn cho thấy cho người lấy vùng có cho từ cho ngày cho phùng cho một vào một cho đậy cho về xảy bóp xoắn rồi thángbảy nhằn ta cho cho cho\n",
      "Iter 550. \n",
      "    Loss 11795.013671875. Time 9.029802560806274\n",
      "anh người được một người chàng người người người được chồng có người chiều người có có có người người không có người anh anh một xưng có nõn vư ngươi đuổi người một người có được khi người đản đến một người anh có đã người một anh không ư có chàng có người đến được người người người phải một người của có một được có người có có làm anh một đạo người người đến được người một một đủ anh người anh đáp nhưng đã đã rất có không thết anh được một người người người có được người được không một người được thầm có được một có người thấy người người người có ở người giải được anh của người người có nghe một mãnh phấn người được một có chàng có được người người thơ vị người người anh cả đến người người 196\n",
      "Iter 600. \n",
      "    Loss 11741.4482421875. Time 9.031046390533447\n",
      "anh rèn     lào một ghẻ ngoạn lại cánh ki ở   vợ lại một húy giòn  đến đường      anh chồng một một ưu đến đến      trong 4 cho không hài huân một leo một mà trí chu  lại   nghỉ một một thốt chàng khiếp            hiểu tù mần        biếng ở khan bắt nhưng   ăn biện ra      còn đến        mày đến gửi          người già đak thế khán   vạch đi không người lại  nhì kém huế ðiều thì    đâu một một mất không nhấp  đến được ra anh ðến đánh một chồng che            đến phạt  đi thất càn một              hay chân một một    chén không thím không\n",
      "Iter 650. \n",
      "    Loss 11085.9296875. Time 9.015157222747803\n",
      "anh và và lại lại lại và lại và vào và và trị khác phũ và và và và và và và lại và và lại con cây và và lại lại và nguôi và và và lại người người người và lại và lại và lại và lại cho và lại và lại và người và và và con và và lại vĩ người lại và sát lại lại cây và và lại và cây lại lại và lại lại người về và người và lại và và lại và và vào và lại lại lại lại người và người và lại lại người lại vào lại và và và lại con và lại lại rập và lại cầu và con lại người và người lại con lại lại và một và và khản và và người người người lại và lại và và lại lại và người lại một\n",
      "Iter 700. \n",
      "    Loss 11785.203125. Time 9.01008677482605\n",
      "anh người cho đi bù cho vài cho và cho thì cho đến thì cho ngày ? thì toán rồi cho người cho cho cho bà cho cho cho tát nhà và cho không cháy cho gọt thì cho một nhường cho cho như đi cho hững con cho nhà không làm cho con cho mình ác không cho lại cho cho cho môi điạ nhà thì khoét dô nhà cho một có nhà không nhà cho nhà không cho chỉ cho khêu lá đi cán cho thì rồi có một đi con không đi thì không riết và mao thì hắc bà cho một toà cho một cho của không cho một con ở một thầy nhà nhe anh không một không cho nhà rồi phục cho thì cho đi cho thì cho cho cho một bỏ một con cho cho cho nhưng cho cho thấy cho những không trúng\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 750. \n",
      "    Loss 11323.00390625. Time 9.007134437561035\n",
      "anh một một người một một một một một một người một người một một một một một người một một một một một một một một người người một một một một một một người một một một người một một người một một một một một một một người một người một một một một một một người một một một một một một người một một một một người một một một người một một một một một một một một một một người một một một người một một một người một một một người một người một người một một người một một một một người một một một người một một người một một một người một một người một một một một một người người một người một một một một một một một một một một người hụp một một người người một\n",
      "Iter 800. \n",
      "    Loss 12558.7783203125. Time 9.009844064712524\n",
      "anh bà một không một một một một một một một một một một một một một anh làm một một một người một bà một một anh một bà làm một một một một một một không người làm bà làm làm một bà một một người làm làm một anh không một một một người một một bà nào của một một làm một một người một người một cô một bà một người người một người một một người một một một một một không một một một người một một một một một một một một người một anh một một bà một một một người một một người làm làm một một một bà một bà làm một một người một một một một một một một một một một không một một một một người một một một bà một người một anh một người\n",
      "Iter 850. \n",
      "    Loss 11342.2001953125. Time 9.017137050628662\n",
      "anh một một người một một một một không thấy một một một khi một một một một một một một một một một một người một một một một khi một một một một một một khi một người một một một khi một một một khi người một một một một một một một một một người một một khi một một người một một người một một một một một một một một một một một một khi một một một một một một một một một một một một con một một một một một một một người người một một một người bé một một một một một khi một thấy một người một một một một một một một một một một một một người một khi thấy một một một một khi người một một một một một một một một một một không\n",
      "Iter 900. \n",
      "    Loss 11157.8037109375. Time 9.022972345352173\n",
      "anh người một con người người người người người một người người một người người con người người người con người người người người người con người người con một người người người người người người một người con một người người người người người người con người con người người một người người người người người người người người người con con người người người người người một người người một con một người một người một người người người một người một con người người người người con người người người người người người người người người người người người con người một người một người người con con một con người một người một người một con con một người người người người một người người người một một người con một con một người con con con người một người người con người con một người người\n",
      "Iter 950. \n",
      "    Loss 11162.72265625. Time 9.025815963745117\n",
      "anh một ông không ông làm lại lại thì ông một ông người làm về thì ông một ông cũng anh làm ông làm một người của người làm một ông làm một ông về cho anh làm không ông làm mà ông không người làm lên làm thì cô ông không người một người làm làm thì không ông làm cũng người làm làm ra thào mà người thì không ông làm không người đã em cầm lại một có người một ông lại thì ông làm không người làm cho ông thì ông ông không người người một người ông lại lại mà người thứ không không người làm đi lại mà ông của ông thì người một không ông một người một ông lại thì ông người không ông làm làm thì ông một ông làm một ông lại mà một ông lại làm thì ông ông không\n",
      "Iter 1000. \n",
      "    Loss 10784.32421875. Time 9.042726755142212\n",
      "anh người người người người người người người người người người người người người người người người một người người người người người người người người một người người người người người người người người người người người một người người người người người người người người người người người người người người người người người người người người người người một người người người người người người người người một người người người người người người người người người người người người người người người người người người người người người một người người người người người người người người người người người người một người người người người con người một người người người người người người người người người một người người người người người người người người người người một người người một người người người người người người người người người người người người người một\n",
      "Iter 1050. \n",
      "    Loss 10639.451171875. Time 9.025195360183716\n",
      "anh người người người người người người người người người người người người người người người người người người người người người người người người một người người người người một người người người người người người người người người người người người người người một người người người người người người người người người người người người người người người người người người người người người một người người một người người người người người người người người một người người người người người người người người người người người người người người người người người người người người người người người người người người người một người người người một người người người người một người người một người người người người người người người người người người người người người người người người người người người người người người người người người người người người người người một\n",
      "Iter 1100. \n",
      "    Loss 10972.23046875. Time 9.114225149154663\n",
      "anh người người người người thấy người thấy thấy thấy người người thấy người thấy người người người người thấy người người người người người người người người người người một người thấy người người người người thấy người người người thấy thấy thấy người người người người thấy người người thấy người thấy người người người thấy người người người người người thấy người người người người người người thấy người người thấy thấy thấy người người người thấy người thấy người người người thấy người người người thấy người thấy thấy người người thấy thấy người người người người người thấy người người thấy người người người thấy thấy thấy thấy thấy người người thấy thấy thấy người người thấy người thấy người người người thấy người người người thấy người người người người thấy thấy thấy thấy người thấy người người người người người thấy thấy người người\n"
     ]
    }
   ],
   "source": [
    "lm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
